{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pylab import *\n",
    "import gc\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_directory = '../data/'\n",
    "# class_system = 'IPC4'\n",
    "# sample_start = 0\n",
    "# max_sample = 773000\n",
    "# sample_length = 1000\n",
    "# n_combine = 100000\n",
    "# rescale_z = True\n",
    "# relatedness_types = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdfs = {}\n",
    "\n",
    "for relatedness in relatedness_types:\n",
    "    pdfs[relatedness] = {}\n",
    "    for popularity in popularity_types:\n",
    "        pdfs[relatedness][popularity] = {}\n",
    "        for m in ['data', 'entries']:\n",
    "            pdfs[relatedness][popularity]['data'] = []\n",
    "            pdfs[relatedness][popularity]['entries'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_sparse_series(list_of_series):\n",
    "    return pd.concat(list_of_series).groupby(level=arange(shape(list_of_series[0].index.levels)[0]).tolist()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "t = time()\n",
    "while sample_start<max_sample:\n",
    "    \n",
    "    f = data_directory+ 'Predictive_Models/PDF/samples/agent_entry_data_%s_sample_%i_%i_agents/'%(class_system,\n",
    "                                                                                                         sample_start,\n",
    "                                                                                                         sample_start+sample_length)              \n",
    "    for relatedness in relatedness_types:\n",
    "        g = f+relatedness\n",
    "        if 'z_score' in relatedness and rescale_z: \n",
    "            g += '_rescaled'\n",
    "        g += '/'\n",
    "        for popularity in popularity_types:\n",
    "            h = g+popularity+'/'\n",
    "            pdfs[relatedness][popularity]['data'].append(pd.read_hdf(h+'data.h5', 'data'))\n",
    "            pdfs[relatedness][popularity]['entries'].append(pd.read_hdf(h+'data.h5', 'entries'))\n",
    "\n",
    "    gc.collect()\n",
    "    if not sample_start%(n_combine) and sample_start!=0:\n",
    "        print(\"%.1f minutes to access %i samples (now at %i)\"%(((time()-t)/60), n_combine, sample_start))\n",
    "        t = time()\n",
    "        for relatedness in relatedness_types:\n",
    "            for popularity in popularity_types:\n",
    "                pdfs[relatedness][popularity]['data'] = [add_sparse_series(pdfs[relatedness][popularity]['data'])]\n",
    "                pdfs[relatedness][popularity]['entries'] = [add_sparse_series(pdfs[relatedness][popularity]['entries'])]    \n",
    "        gc.collect()\n",
    "        print(\"%.1f minutes to combine %i samples (now at %i)\"%(((time()-t)/60), n_combine, sample_start))\n",
    "        t = time()\n",
    "    sample_start += sample_length\n",
    "print(\"%.1f minutes to access samples\"%((time()-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "for relatedness in relatedness_types:\n",
    "    for popularity in popularity_types:\n",
    "        pdfs[relatedness][popularity]['data'] = add_sparse_series(pdfs[relatedness][popularity]['data'])\n",
    "        pdfs[relatedness][popularity]['entries'] = add_sparse_series(pdfs[relatedness][popularity]['entries'])\n",
    "print('%.1f to combine last samples'%(time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cumulate(s):\n",
    "    return s.sort_index(level='Application_Year').groupby(level=[1,2,3,4]).cumsum()\n",
    "\n",
    "import os\n",
    "def create_directory_if_not_existing(f):\n",
    "    try:\n",
    "        os.makedirs(f)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_directory_if_not_existing(data_directory+'Predictive_Models/')\n",
    "\n",
    "f = data_directory+'Predictive_Models/PDF/'\n",
    "for relatedness in relatedness_types:\n",
    "    g = f+relatedness\n",
    "    if 'z_score' in relatedness and rescale_z: \n",
    "        g += '_rescaled'\n",
    "    g += '/'\n",
    "    create_directory_if_not_existing(f)\n",
    "    for popularity in popularity_types:\n",
    "        h = g+popularity+'/'\n",
    "        create_directory_if_not_existing(h)\n",
    "        pdfs[relatedness][popularity]['data'].to_hdf(h+'year_by_year.h5', 'data', complib='blosc', complevel=9)\n",
    "        pdfs[relatedness][popularity]['entries'].to_hdf(h+'year_by_year.h5', 'entries', complib='blosc', complevel=9)\n",
    "        \n",
    "        store = pd.HDFStore(h+'cumulative.h5', complib='blosc', complevel=9)\n",
    "        for year in arange(1977,2010+1):\n",
    "            e_this_year = pdfs[relatedness][popularity]['entries'].ix[:year].groupby(level=[1,2,3,4]).sum()\n",
    "            d_this_year = pdfs[relatedness][popularity]['data'].ix[:year].groupby(level=[1,2,3,4]).sum()\n",
    "            store.put('entries/year_%i'%year, e_this_year)\n",
    "            store.put('data/year_%i'%year, d_this_year)\n",
    "            store.put('pdf/year_%i'%year, (e_this_year/d_this_year).fillna(0))\n",
    "        store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
