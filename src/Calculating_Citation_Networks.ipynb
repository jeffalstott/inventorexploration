{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {}
   },
   "source": [
    "Setup\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomization_id = 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "t = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_directory = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "===\n",
    "Define What Class System to Analyze\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_system = 'USPC'\n",
    "# class_system = 'IPC'\n",
    "# class_system = 'IPC4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are We Making a Randomized Control?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomized_control = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Years are We Calculating Networks for?\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target_years = [1980]#'all' #Calculate a network for every year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Years of History are We Using?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_years = None\n",
    "# n_years = 5\n",
    "\n",
    "if n_years is None or n_years=='all' or n_years=='cumulative':\n",
    "    n_years_label = ''\n",
    "else:\n",
    "    n_years_label = '%i_years_'%n_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Metrics are We Calculating?\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citation_metrics = ['Class_Cites_Class_Count',\n",
    "           'Class_Cited_by_Class_Count',]\n",
    "#            'Class_Cites_Class_Input_Cosine_Similarity',\n",
    "#            'Class_Cites_Class_Output_Cosine_Similarity',\n",
    "#            'Class_Cites_Patent_Input_Cosine_Similarity',\n",
    "#            'Patent_Cites_Class_Output_Cosine_Similarity',\n",
    "# #            'Class_Cites_Patent_Input_Jaccard_Similarity',\n",
    "# #            'Patent_Cites_Class_Output_Jaccard_Similarity',\n",
    "#            'Class_CoCitation_Count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {}
   },
   "source": [
    "Import Citation Data\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "citations = pd.read_hdf(data_directory+'citations_organized.h5', 'citations')\n",
    "\n",
    "\n",
    "class_lookup = pd.read_hdf(data_directory+'citations_organized.h5', \n",
    "                           '%s_class_lookup'%class_system)\n",
    "\n",
    "#Set columns of the patent classification system we're interested in to the default names, without a class system tag.\n",
    "for column in citations.columns:\n",
    "    if class_system in column:\n",
    "        new_name = column.replace('_'+class_system, \"\")\n",
    "        citations.rename(columns={column: new_name}, inplace=True)\n",
    "        \n",
    "citations = citations[['Citing_Patent', 'Cited_Patent', \n",
    "                      'Year_Citing_Patent', 'Class_Citing_Patent',\n",
    "                      'Year_Cited_Patent', 'Class_Cited_Patent',\n",
    "                      'Same_Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop citations where one of the patents has an undefined class. \n",
    "### This would happen if the patent had been assigned to a class that is not included\n",
    "### in the set of classes we're analyzing (defined in data/class_lookup_tables.h5)\n",
    "### In practice this means about 350 patents are removed, which between them have 100 classes\n",
    "### that aren't represented anywhere else. We don't know if these small or unique classes are\n",
    "### clerical errors or if they were classes the patent office experimented with creating and\n",
    "### then dropped; all these classes are not in the current IPC system, so we treat them as noise\n",
    "### and drop them.\n",
    "citations.dropna(subset=['Class_Citing_Patent', 'Class_Cited_Patent'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if randomized_control:\n",
    "    patent_attributes = pd.read_hdf(data_directory+'citations_organized.h5', 'patent_attributes')\n",
    "    \n",
    "    for column in patent_attributes.columns:\n",
    "        if class_system in column:\n",
    "            new_name = column.replace('_'+class_system, \"\")\n",
    "            patent_attributes.rename(columns={column: new_name}, inplace=True)\n",
    "\n",
    "    patent_attributes = patent_attributes[['Year', 'Class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {}
   },
   "source": [
    "Calculate and Store Class-Class Similarity Metrics\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time()\n",
    "        print('%2.2f sec' % (te-ts))\n",
    "        return result\n",
    "    return timed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if randomized_control:\n",
    "#     ### Define functions to generate random controls\n",
    "#     @timeit\n",
    "#     def randomize_citations(citations,\n",
    "#                             patent_attributes=patent_attributes):\n",
    "#         citations_randomized = citations.copy()\n",
    "\n",
    "#         ### Take the same-class citations of every class and permute them.\n",
    "#         same_class_ind = citations_randomized['Same_Class']==True\n",
    "#         citations_randomized.ix[same_class_ind, 'Cited_Patent'] = citations_randomized.ix[same_class_ind].groupby(['Year_Citing_Patent', \n",
    "#             'Year_Cited_Patent', \n",
    "#             'Class_Citing_Patent', \n",
    "#             ])['Cited_Patent'].transform(permutation)\n",
    "\n",
    "#         ### Take the cross-class citations and permute them.\n",
    "#         cross_class_ind = -same_class_ind\n",
    "#         citations_randomized.ix[cross_class_ind, 'Cited_Patent'] = citations_randomized.ix[cross_class_ind].groupby(['Year_Citing_Patent', \n",
    "#             'Year_Cited_Patent', \n",
    "#             ])['Cited_Patent'].transform(permutation)\n",
    "\n",
    "#         ### Drop patent attributes (which are now inaccurate for the cited patent) and bring them in from patent_attributes\n",
    "#         citations_randomized = citations_randomized[['Citing_Patent', 'Cited_Patent', 'Same_Class']]\n",
    "\n",
    "#         citations_randomized = citations_randomized.merge(patent_attributes, \n",
    "#                         left_on='Citing_Patent', \n",
    "#                         right_index=True,\n",
    "#                         )\n",
    "\n",
    "#         citations_randomized = citations_randomized.merge(patent_attributes, \n",
    "#                         left_on='Cited_Patent', \n",
    "#                         right_index=True,\n",
    "#                         suffixes=('_Citing_Patent','_Cited_Patent'))\n",
    "#         return citations_randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if randomized_control:\n",
    "    import BiRewire as br\n",
    "#     import rpy2.robjects as ro\n",
    "#     from rpy2.robjects.packages import importr\n",
    "#     from rpy2.robjects.numpy2ri import numpy2ri\n",
    "#     ro.numpy2ri.activate()\n",
    "#     importr('igraph')\n",
    "#     importr('BiRewire')\n",
    "    \n",
    "    ### Define functions to generate random controls\n",
    "    @timeit\n",
    "    def randomize_citations(citations,\n",
    "                            patent_attributes=patent_attributes):\n",
    "        citations_randomized = citations.copy()\n",
    "\n",
    "        ### Take the same-class citations of every class and permute them.\n",
    "#         from time import sleep\n",
    "#         sleep(rand()*10)\n",
    "        print(\"Randomizing Same-Class Citations\")\n",
    "        same_class_ind = citations_randomized['Same_Class']==True\n",
    "        grouper = citations_randomized.ix[same_class_ind].groupby(['Year_Citing_Patent', \n",
    "                                                                   'Year_Cited_Patent', \n",
    "                                                                   'Class_Citing_Patent', \n",
    "                                                                  ])[['Citing_Patent', \n",
    "                                                                      'Cited_Patent']]\n",
    "        print(\"%i groups\"%(len(grouper)))\n",
    "\n",
    "        citations_randomized.ix[same_class_ind, ['Citing_Patent', \n",
    "                                                 'Cited_Patent']\n",
    "                                ] = grouper.apply(randomize_citations_helper)\n",
    "\n",
    "        ### Take the cross-class citations and permute them.\n",
    "#         from time import sleep\n",
    "#         sleep(rand()*10)\n",
    "        print(\"Randomizing Cross-Class Citations\")        \n",
    "        cross_class_ind = -same_class_ind\n",
    "        grouper = citations_randomized.ix[cross_class_ind].groupby(['Year_Citing_Patent', \n",
    "                                                                   'Year_Cited_Patent', \n",
    "                                                                  ])[['Citing_Patent', \n",
    "                                                                      'Cited_Patent']]\n",
    "        print(\"%i groups\"%(len(grouper)))\n",
    "        citations_randomized.ix[cross_class_ind, ['Citing_Patent', \n",
    "                                                 'Cited_Patent']\n",
    "                                ] = grouper.apply(randomize_citations_helper)\n",
    "        \n",
    "        ### Drop patent attributes (which are now inaccurate for both the citing and cited patent) and bring them in from patent_attributes\n",
    "        citations_randomized = citations_randomized[['Citing_Patent', 'Cited_Patent', 'Same_Class']]\n",
    "\n",
    "        citations_randomized = citations_randomized.merge(patent_attributes, \n",
    "                        left_on='Citing_Patent', \n",
    "                        right_index=True,\n",
    "                        )\n",
    "\n",
    "        citations_randomized = citations_randomized.merge(patent_attributes, \n",
    "                        left_on='Cited_Patent', \n",
    "                        right_index=True,\n",
    "                        suffixes=('_Citing_Patent','_Cited_Patent'))\n",
    "        return citations_randomized\n",
    "\n",
    "\n",
    "#     @timeit\n",
    "    def randomize_citations_helper(citing_cited):\n",
    "        \n",
    "        ind = citing_cited.index\n",
    "        rewired_output = citing_cited.copy()\n",
    "\n",
    "\n",
    "        Citing_lookup = pd.Series(index=citing_cited.Citing_Patent.unique(),\n",
    "                                  data=1+arange(citing_cited.Citing_Patent.nunique()))\n",
    "        Cited_lookup = pd.Series(index=citing_cited.Cited_Patent.unique(),\n",
    "                                 data=1+arange(citing_cited.Cited_Patent.nunique()))\n",
    "\n",
    "        n_Citing = len(Citing_lookup)\n",
    "        n_Cited = len(Cited_lookup)\n",
    "        if n_Cited*n_Citing==len(ind): #The graph is fully connected, and so can't be rewired\n",
    "            return rewired_output\n",
    "\n",
    "        citing_cited.Citing_Patent = Citing_lookup.ix[citing_cited.Citing_Patent].values\n",
    "        citing_cited.Cited_Patent = Cited_lookup.ix[citing_cited.Cited_Patent].values\n",
    "        citing_cited.Cited_Patent += n_Citing\n",
    "\n",
    "#         ro.globalenv['citing_cited'] = ro.Vector(citing_cited.values.ravel(order='C'))\n",
    "#         ro.globalenv['n_Citing'] = ro.default_py2ri(n_Citing)\n",
    "#         ro.globalenv['n_Cited'] = ro.default_py2ri(n_Cited)    \n",
    "#         ro.r('g = graph.bipartite(c(rep(T, n_Citing), rep(F, n_Cited)), citing_cited)')\n",
    "#         ro.r('h = birewire.rewire.bipartite(g, verbose=FALSE, exact=TRUE)')\n",
    "#         z = array(ro.r('z = get.edgelist(h)')).astype('int')\n",
    "        this_rewiring = br.Rewiring(data=citing_cited.values,\n",
    "                                   type_of_array='edgelist_b',\n",
    "                                   type_of_graph='bipartite')\n",
    "        this_rewiring.rewire(verbose=0)   \n",
    "        z = this_rewiring.data_rewired\n",
    "\n",
    "\n",
    "        Citing_lookup = pd.DataFrame(Citing_lookup).reset_index().set_index(0)\n",
    "        Cited_lookup = pd.DataFrame(Cited_lookup).reset_index().set_index(0)\n",
    "\n",
    "        citing_patents = Citing_lookup.ix[z[:,0]].values.flatten()\n",
    "        cited_patents = Cited_lookup.ix[z[:,1]-n_Citing].values.flatten()\n",
    "        \n",
    "#         df = pd.DataFrame(index=ind,\n",
    "#                          columns=['Citing_Patent', 'Cited_Patent'],\n",
    "#                          )\n",
    "        rewired_output['Citing_Patent'] = citing_patents\n",
    "        rewired_output['Cited_Patent'] = cited_patents\n",
    "        return rewired_output#citing_patents, cited_patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all(citations.Citing_Patent.value_counts()==citations_rewired.Citing_Patent.value_counts())\n",
    "# all(citations.Cited_Patent.value_counts()==citations_rewired.Cited_Patent.value_counts())\n",
    "# all(citations.Year_Citing_Patent.value_counts()==citations_rewired.Year_Citing_Patent.value_counts())\n",
    "# all(citations.Year_Cited_Patent.value_counts()==citations_rewired.Year_Cited_Patent.value_counts())\n",
    "# all(citations.Class_Cited_Patent.value_counts()==citations_rewired.Class_Cited_Patent.value_counts())\n",
    "# all(citations.Class_Citing_Patent.value_counts()==citations_rewired.Class_Citing_Patent.value_counts())\n",
    "# all(citations.groupby(['Year_Citing_Patent', 'Year_Cited_Patent'])['Same_Class'].count() == citations_rewired.groupby(['Year_Citing_Patent', 'Year_Cited_Patent'])['Same_Class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_erroneous_cross_class = (citations_rewired['Class_Cited_Patent']==citations_rewired['Class_Citing_Patent'] * ~citations_rewired['Same_Class']).sum()\n",
    "# n_erroneous_cross_class/citations.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Establish metrics and how to calculate them\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "@timeit\n",
    "def cosine_similarities(citation_counts):\n",
    "    similarities = 1-pairwise_distances(citation_counts, metric=\"cosine\")\n",
    "    \n",
    "#     #In case there are any classes not covered in this citation count matrix, they will \n",
    "#     #be the ones at the end (e.g. if there are 430 classes, this citation count matrix could\n",
    "#     #only go up to 420 classes, in which case the remaining 10 classes should all have 0s)\n",
    "#     all_similarities = zeros((max(classes)+1, max(classes)+1))\n",
    "#     all_similarities[:present_similarities.shape[0], \n",
    "#                      :present_similarities.shape[1]] = present_similarities\n",
    "    \n",
    "    return pd.DataFrame(data=similarities,\n",
    "                        columns=classes,\n",
    "                        index=classes)\n",
    "\n",
    "\n",
    "@timeit\n",
    "def jaccard_similarities(citation_counts):\n",
    "    return pd.DataFrame(data=pairwise_distances(citation_counts>0, metric=jaccard_helper),\n",
    "                        columns=classes,\n",
    "                        index=classes)\n",
    "\n",
    "from scipy.sparse import find as sfind\n",
    "def jaccard_helper(x,y):\n",
    "    I, J, V = sfind(x)\n",
    "    I1, J1, V1 = sfind(y)\n",
    "    J = set(J)\n",
    "    J1 = set(J1)\n",
    "    try:\n",
    "        return len(J.intersection(J1))/len(J.union(J1))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "@timeit\n",
    "def calculate_citation_counts(citations, \n",
    "                              relation='class_cites_class',\n",
    "                              up_to_year=False):\n",
    "    if up_to_year and up_to_year!='all':\n",
    "        citations = citations[citations['Year_Citing_Patent']<=up_to_year]\n",
    "\n",
    "\n",
    "    if relation=='class_cites_class':\n",
    "        ### Calculate citation counts from each class to each class\n",
    "        citation_counts = citations.groupby(['Class_Citing_Patent', 'Class_Cited_Patent'\n",
    "                                          ])['Citing_Patent'].count()        \n",
    "        \n",
    "        citation_counts = pd.DataFrame(citation_counts)\n",
    "        citation_counts.rename(columns={'Citing_Patent': 'Count'}, inplace=True)\n",
    "        citation_counts.reset_index(inplace=True)\n",
    "        val = citation_counts['Count'].values\n",
    "        x = citation_counts['Class_Citing_Patent'].values\n",
    "        y = citation_counts['Class_Cited_Patent'].values\n",
    "        dims = (len(classes), len(classes))\n",
    "        \n",
    "    elif relation=='patent_cites_class':\n",
    "        ### Calculate citation counts from each patent to each class\n",
    "        citation_counts = citations.groupby(['Citing_Patent', 'Class_Cited_Patent', \n",
    "                                              ])['Citing_Patent'].count()\n",
    "        \n",
    "        citation_counts = pd.DataFrame(citation_counts)\n",
    "        citation_counts.rename(columns={'Citing_Patent': 'Count'}, inplace=True)\n",
    "        citation_counts.reset_index(inplace=True)\n",
    "        val = citation_counts['Count'].values\n",
    "        x = citation_counts['Citing_Patent'].values\n",
    "        y = citation_counts['Class_Cited_Patent'].values\n",
    "        dims = (max(x)+1, len(classes))\n",
    "        \n",
    "    elif relation=='class_cites_patent':\n",
    "        ### Calculate citation counts from each class to each patent\n",
    "        citation_counts = citations.groupby(['Cited_Patent', 'Class_Citing_Patent', \n",
    "                                          ])['Cited_Patent'].count()\n",
    "        #Note: Typical convention is to read FROM rows TO columns (i.e. the arrows or citations go from the row value)\n",
    "        #to the column value. This dataframe breaks that convention (i.e. does the reverse). The reason for this is\n",
    "        #that in pandas it is easier to have a bazillion rows than to have a bazillion columns. Since we have far more\n",
    "        #individual patents than individual classes (order of 4 million vs order of 100), we are making the patents the\n",
    "        #rows and the classes the columns. So, be careful when using this output in the future. Be sure to transpose it\n",
    "        #when needed!\n",
    "        \n",
    "        citation_counts = pd.DataFrame(citation_counts)\n",
    "        citation_counts.rename(columns={'Cited_Patent': 'Count'}, inplace=True)\n",
    "        citation_counts.reset_index(inplace=True)\n",
    "        val = citation_counts['Count'].values\n",
    "        x = citation_counts['Cited_Patent'].values\n",
    "        y = citation_counts['Class_Citing_Patent'].values\n",
    "        dims = (max(x)+1, len(classes))\n",
    "    \n",
    "    from scipy.sparse import csr_matrix\n",
    "    citation_counts = csr_matrix((val, (x,y)), shape=dims)\n",
    "    \n",
    "#     citation_counts = citation_counts.unstack()\n",
    "#     citation_counts.sort(axis=1,inplace=True)    \n",
    "#     citation_counts.sort(axis=0,inplace=True)    \n",
    "#     citation_counts.fillna(0, inplace=True)\n",
    "\n",
    "    return citation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classes = sort(list(set(citations['Class_Cited_Patent'].unique()).union(citations['Class_Citing_Patent'].unique())))\n",
    "classes = arange(len(class_lookup))\n",
    "years = set(citations['Year_Cited_Patent'].unique()).union(citations['Year_Citing_Patent'].unique())\n",
    "years = list(range(min(years), max(years)+1))\n",
    "\n",
    "if target_years is None or target_years=='all':\n",
    "    target_years = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def cocitation_counts(citations, \n",
    "                      up_to_year=False):\n",
    "    if up_to_year and up_to_year!='all':\n",
    "        citations = citations[citations['Year_Citing_Patent']<=up_to_year]\n",
    "\n",
    "    import scipy.sparse\n",
    "    patent_class_citations = scipy.sparse.csr_matrix((ones_like(citations['Citing_Patent']),\n",
    "                                                      (citations['Citing_Patent'].values, \n",
    "                                                       citations['Class_Cited_Patent'].values)))\n",
    "\n",
    "    present_cocitation_counts = (patent_class_citations.T * patent_class_citations).todense()\n",
    "    \n",
    "    all_cocitation_counts = zeros((max(classes)+1, max(classes)+1))\n",
    "    all_cocitation_counts[:present_cocitation_counts.shape[0], \n",
    "                          :present_cocitation_counts.shape[1]] = present_cocitation_counts\n",
    "    \n",
    "    return all_cocitation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_citation_networks(citations,\n",
    "                                metrics,\n",
    "                                target_years,\n",
    "                                classes=classes,\n",
    "                                n_years=n_years\n",
    "                                ):\n",
    "    networks = pd.Panel4D(labels=metrics,\n",
    "                          items=target_years,\n",
    "                          major_axis=classes,\n",
    "                          minor_axis=classes,\n",
    "                          dtype='float64')\n",
    "\n",
    "    for year in target_years:\n",
    "        print(year)\n",
    "#         these_citations = citations[citations['Year_Citing_Patent']<=year]\n",
    "        if n_years is None or n_years=='all' or n_years=='cumulative':\n",
    "            these_citations = citations[citations['Year_Citing_Patent']<=year]\n",
    "        else:\n",
    "            these_citations = citations[((citations['Year_Citing_Patent']<=year) & \n",
    "                                           (citations['Year_Citing_Patent']>(year-n_years)))]\n",
    "        \n",
    "        if 'Class_CoCitation_Count' in metrics:\n",
    "            print('Class_CoCitation_Count')\n",
    "            networks.ix['Class_CoCitation_Count', year,:,:] = cocitation_counts(these_citations)\n",
    "        \n",
    "        citation_counts = calculate_citation_counts(these_citations,\n",
    "                                                    relation='class_cites_class')\n",
    "        if 'Class_Cites_Class_Count' in metrics:\n",
    "            print('Class_Cites_Class_Count')\n",
    "            networks.ix['Class_Cites_Class_Count', year,:,:] = array(citation_counts.todense())\n",
    "        if 'Class_Cited_by_Class_Count' in metrics:\n",
    "            print('Class_Cited_by_Class_Count')\n",
    "            networks.ix['Class_Cited_by_Class_Count', year,:,:] = array(citation_counts.todense().T)\n",
    "        \n",
    "        if 'Class_Cites_Class_Input_Cosine_Similarity' in metrics:\n",
    "            print('Class_Cites_Class_Input_Cosine_Similarity')\n",
    "            networks.ix['Class_Cites_Class_Input_Cosine_Similarity', year,:,:] = cosine_similarities(citation_counts)\n",
    "        if 'Class_Cites_Class_Output_Cosine_Similarity' in metrics:\n",
    "            print('Class_Cites_Class_Output_Cosine_Similarity')\n",
    "            networks.ix['Class_Cites_Class_Output_Cosine_Similarity', year,:,:] = cosine_similarities(citation_counts.T)\n",
    "\n",
    "        citation_counts = calculate_citation_counts(these_citations,\n",
    "                                                    relation='class_cites_patent')\n",
    "        if 'Class_Cites_Patent_Input_Cosine_Similarity' in metrics:\n",
    "            print('Class_Cites_Patent_Input_Cosine_Similarity')\n",
    "            networks.ix['Class_Cites_Patent_Input_Cosine_Similarity', year,:,:] = cosine_similarities(citation_counts.T)\n",
    "        \n",
    "        if 'Class_Cites_Patent_Input_Jaccard_Similarity' in metrics:\n",
    "            print('Class_Cites_Patent_Input_Jaccard_Similarity')\n",
    "            networks.ix['Class_Cites_Patent_Input_Jaccard_Similarity', year,:,:] = jaccard_similarities(citation_counts.T)\n",
    "\n",
    "        citation_counts = calculate_citation_counts(these_citations,\n",
    "                                                    relation='patent_cites_class')\n",
    "        if 'Patent_Cites_Class_Output_Cosine_Similarity' in metrics:\n",
    "            print('Patent_Cites_Class_Output_Cosine_Similarity')\n",
    "            networks.ix['Patent_Cites_Class_Output_Cosine_Similarity', year,:,:] = cosine_similarities(citation_counts.T)\n",
    "        \n",
    "        if 'Patent_Cites_Class_Output_Jaccard_Similarity' in metrics:\n",
    "            print('Patent_Cites_Class_Output_Jaccard_Similarity')\n",
    "            networks.ix['Patent_Cites_Class_Output_Jaccard_Similarity', year,:,:] = jaccard_similarities(citation_counts.T)\n",
    "        \n",
    "\n",
    "    return networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if randomized_control:\n",
    "    citations = randomize_citations(citations)\n",
    "    print(\"Time until randomizations are done: %.2f\"%(time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# citations_rewired = randomize_citations(citations)\n",
    "# counts_empirical = calculate_citation_counts(citations, relation='class_cites_class').todense()\n",
    "# counts_rewired = calculate_citation_counts(citations_rewired, relation='class_cites_class').todense()\n",
    "# networks_rewired = calculate_citation_networks(citations_rewired, metrics, target_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n",
      "3.79 sec\n",
      "Class_Cites_Class_Count\n",
      "Class_Cited_by_Class_Count\n",
      "11.68 sec\n",
      "18.88 sec\n"
     ]
    }
   ],
   "source": [
    "networks = calculate_citation_networks(citations, citation_metrics, target_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time until calculations are done: 415.39\n"
     ]
    }
   ],
   "source": [
    "print(\"Time until calculations are done: %.2f\"%(time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "networks.major_axis = class_lookup.index[networks.major_axis]\n",
    "networks.minor_axis = class_lookup.index[networks.minor_axis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if randomized_control:\n",
    "    file_name = 'synthetic_control_citations_%s%s_%i.h5'%(n_years_label, class_system, randomization_id)\n",
    "    \n",
    "#     file_name = '5_years_'+file_name\n",
    "    \n",
    "    store = pd.HDFStore(data_directory+'Class_Relatedness_Networks/citations/controls/%s/%s'%(class_system,file_name),\n",
    "                    mode='w', table=True)\n",
    "    store.put('/synthetic_citations_'+class_system, networks, 'table', append=False)\n",
    "    store.close()\n",
    "else:\n",
    "    store = pd.HDFStore(data_directory+'Class_Relatedness_Networks/citations/class_relatedness_networks_citations.h5',\n",
    "                        mode='a', table=True)\n",
    "    store.put('/empirical_citations_'+n_years_label+class_system, networks, 'table', append=False)\n",
    "    store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 460.86\n"
     ]
    }
   ],
   "source": [
    "print(\"Total runtime: %.2f\"%(time()-t))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "css": [
   ""
  ],
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
