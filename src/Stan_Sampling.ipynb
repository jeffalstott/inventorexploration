{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_chains = 50\n",
    "# chains_start = 0\n",
    "# num_warmup = 300\n",
    "# num_samples = 300\n",
    "# n_observations = 'full'#100000\n",
    "# data_directory = '../data/'\n",
    "# from os import path\n",
    "# abs_path_data_directory = path.abspath(data_directory)+'/'\n",
    "# target = 'entries'\n",
    "# class_system = 'IPC4'\n",
    "\n",
    "# relatedness_type = 'Class_Cited_by_Class_Count'\n",
    "# relatedness = '%s_1_years_percent_positive_all_years_back_mean'%relatedness_type\n",
    "# popularity = 'Class_Patent_Count_1_years_Previous_Year_Percentile'\n",
    "\n",
    "\n",
    "# hit_thresholds = [3,4,5,6]\n",
    "\n",
    "# count_variables = ['Agent_Number_of_Patents_in_Class','Agent_Number_of_Citations_in_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_label = n_observations\n",
    "\n",
    "import os\n",
    "def create_directory_if_not_existing(f):\n",
    "    try:\n",
    "        os.makedirs(f)\n",
    "    except OSError:\n",
    "        pass\n",
    "model_directory = abs_path_data_directory+'Performance_Models/'\n",
    "create_directory_if_not_existing(model_directory+'stan_samples/')\n",
    "create_directory_if_not_existing(model_directory+'stan_samples/{0}/'.format(run_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_store = pd.HDFStore(model_directory+'performance_models.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import system\n",
    "\n",
    "def submit_cmdstan_jobs(model,data_file):\n",
    "    for chain in range(chains_start,chains_start+n_chains):\n",
    "        print(chain)\n",
    "        header = \"\"\"#!/usr/bin/env bash\n",
    "#PBS -l nodes=1:ppn=1\n",
    "#PBS -l walltime=72:00:00\n",
    "#PBS -l mem=4000m\n",
    "#PBS -N chain_{0}_{1}\n",
    "\"\"\".format(data_file, chain)\n",
    "\n",
    "        this_program = (\"{0}{1} \"\n",
    "               \"sample num_samples={3} num_warmup={4} \"\n",
    "               \"data file={0}{2} init=.5 \"\n",
    "               \"output file={0}stan_samples/{6}/output_{2}_{5}.csv\".format(model_directory, \n",
    "                                                             model,\n",
    "                                                             data_file,\n",
    "                                                             num_samples, num_warmup,\n",
    "                                                                           chain, run_label))\n",
    "        this_program = header+this_program\n",
    "        this_job_file = 'jobfiles/chain_{0}_{1}'.format(data_file, chain)\n",
    "\n",
    "\n",
    "        f = open(this_job_file, 'w')\n",
    "        f.write(this_program)\n",
    "        f.close()\n",
    "\n",
    "        system('qsub '+this_job_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store = pd.HDFStore(data_directory+'Agent_Entries/agent_%s_%s.h5'%(target, class_system), mode='r')\n",
    "entries = store['%s_%s_with_performance'%(target, class_system)]\n",
    "store.close()\n",
    "\n",
    "entries['Relatedness'] = entries[relatedness]\n",
    "entries['Popularity']  = entries[popularity]\n",
    "\n",
    "if entries['Relatedness'].max()==100:\n",
    "    entries['Relatedness'] /= 100 \n",
    "\n",
    "if entries['Popularity'].max()==100:\n",
    "    entries['Popularity'] /= 100 \n",
    "\n",
    "entries['Years_to_2010'] = 2010-entries['Application_Year']\n",
    "\n",
    "entries = entries.ix[entries['Years_Since_First_Patent']<40]\n",
    "years_since_first = entries['Years_Since_First_Patent'].values\n",
    "years_since_first[years_since_first==0] = 1\n",
    "entries['Agent_Productivity_Patents'] = entries['Agent_Patent_Number']/years_since_first\n",
    "\n",
    "entries = entries[entries['Application_Year']>1976]\n",
    "entries = entries[entries['Application_Year']<=2005]\n",
    "\n",
    "\n",
    "for c in count_variables:\n",
    "    b = c+'_Mean_for_Year_and_Class_of_New_Immigrants_to_Class'\n",
    "    if entries[c].min()==1:\n",
    "        entries[c] -= 1\n",
    "        entries[b] -= 1\n",
    "    entries = entries[entries[b]>0]\n",
    "\n",
    "\n",
    "def zscore_in_group(x, performance, reference_group):\n",
    "    return ((x[performance]-x[performance+'_Mean_'+reference_group])/\n",
    "                             x[performance+'_STD_'+reference_group])\n",
    "def high_zscore_in_group(x, performance, reference_group, thr):\n",
    "    return (zscore_in_group(x, performance, reference_group)>thr)\n",
    "\n",
    "for thr in hit_thresholds:\n",
    "    entries['Citations_Hit_%i'%thr] = high_zscore_in_group(entries, \n",
    "                                                    'First_Patent_Citations', \n",
    "                                                    'for_Year_and_Class', thr).astype('int')\n",
    "    \n",
    "    \n",
    "entries.to_hdf(model_directory+'entries_for_performance_analysis.h5', 'entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if n_observations=='full' or n_observations=='all':\n",
    "    N = entries.shape[0]\n",
    "else:\n",
    "    N = n_observations\n",
    "from numpy.random import choice\n",
    "ind = choice(entries.index,N, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from patsy import dmatrix\n",
    "from pystan import stan_rdump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "model = 'single_counts_sampling_model'\n",
    "hdf_label = 'counts'\n",
    "formula_variables = ['Relatedness',\n",
    "                     'np.power(Relatedness, 2)',\n",
    "                     'Popularity',\n",
    "                     'np.power(Popularity, 2)',\n",
    "                     'log(Agent_Previous_Citations_to_Class+1)',\n",
    "                     'log(Agent_Productivity_Patents)',\n",
    "                     'log(CoAgent_Previous_Patent_Count_in_Class+1)']\n",
    "formula = \" + \".join(formula_variables)\n",
    "models_store['%s/formula_variables'%hdf_label] = pd.Series(formula_variables)\n",
    "\n",
    "\n",
    "for count_variable in count_variables:\n",
    "    baseline = count_variable+'_Mean_for_Year_and_Class_of_New_Immigrants_to_Class'\n",
    "\n",
    "    predictors = dmatrix(formula, entries.ix[ind])\n",
    "    stan_data = {'y': asarray(entries.ix[ind, count_variable].astype('int')),\n",
    "                 'x': asarray(predictors),\n",
    "                 'N': N,\n",
    "                 'K': predictors.shape[1],\n",
    "                 'baseline': asarray(entries.ix[ind,baseline])\n",
    "             }\n",
    "            \n",
    "    data_file = 'counts_data_{0}_{1}.stan'.format(count_variable, n_observations)\n",
    "    stan_rdump(stan_data, model_directory+data_file)\n",
    "    submit_cmdstan_jobs(model,data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 'hits_sampling_model'\n",
    "hdf_label = 'hits'\n",
    "\n",
    "formula_variables = ['Relatedness',\n",
    "                     'np.power(Relatedness, 2)',\n",
    "                     'np.power(Relatedness, 3)',                     \n",
    "                     'Popularity',\n",
    "                     'np.power(Popularity, 2)',\n",
    "                     'log(Agent_Previous_Citations_to_Class+1)',\n",
    "                     'log(Agent_Productivity_Patents)',\n",
    "                     'log(CoAgent_Previous_Patent_Count_in_Class+1)']\n",
    "formula = \" + \".join(formula_variables)\n",
    "\n",
    "models_store['%s/formula_variables'%hdf_label] = pd.Series(formula_variables)\n",
    "\n",
    "for threshold in hit_thresholds:\n",
    "    predictors = dmatrix(formula, entries.ix[ind])\n",
    "    stan_data = {'y': asarray(entries.ix[ind, 'Citations_Hit_%i'%threshold]),\n",
    "                 'x': asarray(predictors),\n",
    "                 'N': N,\n",
    "                 'K': predictors.shape[1],\n",
    "             }\n",
    "            \n",
    "    data_file = 'hits_data_thr_{0}_{1}.stan'.format(threshold, n_observations)\n",
    "    stan_rdump(stan_data, model_directory+data_file)\n",
    "    submit_cmdstan_jobs(model,data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
